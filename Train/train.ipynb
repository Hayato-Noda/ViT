{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"train.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"cells":[{"cell_type":"code","metadata":{"id":"67b71Ytw5RWu"},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import random\n","from torch.optim.lr_scheduler import StepLR\n","from tqdm.notebook import tqdm\n","\n","class train():\n","  def __init__(self, config):\n","    self.lr = config['lr']\n","    self.gamma = config['gamma']\n","\n","    \n","\n","\n","# loss function\n","criterion = nn.CrossEntropyLoss()\n","# optimizer\n","optimizer = optim.Adam(model.parameters(), lr=self.lr)\n","# scheduler\n","scheduler = StepLR(optimizer, step_size=1, gamma=self.gamma)\n","\n","# 3. Log gradients and model parameters\n","wandb.watch(model, log_freq=100)\n","for epoch in range(config['epochs']):\n","    epoch_loss = 0\n","    epoch_accuracy = 0\n","\n","    for data, label in tqdm(trainloader):\n","        data = data.to(device)\n","        label = label.to(device)\n","\n","        output = model(data)\n","        loss = criterion(output, label)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        acc = (output.argmax(dim=1) == label).float().mean()\n","        epoch_accuracy += acc / len(trainloader)\n","        epoch_loss += loss / len(trainloader)\n","\n","    with torch.no_grad():\n","        epoch_val_accuracy = 0\n","        epoch_val_loss = 0\n","        for data, label in testloader:\n","            data = data.to(device)\n","            label = label.to(device)\n","\n","            val_output = model(data)\n","            val_loss = criterion(val_output, label)\n","\n","            acc = (val_output.argmax(dim=1) == label).float().mean()\n","            epoch_val_accuracy += acc / len(testloader)\n","            epoch_val_loss += val_loss / len(testloader)\n","\n","    print(\n","        f\"Epoch : {epoch+1} - loss : {epoch_loss:.4f} - acc: {epoch_accuracy:.4f} - val_loss : {epoch_val_loss:.4f} - val_acc: {epoch_val_accuracy:.4f}\\n\"\n","    )\n","\n","    # 4. Log metrics to visualize performance\n","    wandb.log({\n","        \"Epoch\": epoch+1,\n","        \"loss\": epoch_loss,\n","        \"acc\": epoch_accuracy,\n","        \"val_loss\" : epoch_val_loss,\n","        \"val_acc\": epoch_val_accuracy\n","        })"],"execution_count":null,"outputs":[]}]}